{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e72bfe",
   "metadata": {},
   "source": [
    "# Scrape Data From Wikipedia Page:  Wikipedia:Size of Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61453c",
   "metadata": {},
   "source": [
    "### Author: <font color='red'> Ben Lenox</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c41e94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "url = \"https://en.wikipedia.org/wiki/Wikipedia:Size_of_Wikipedia\"\n",
    "page = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e4ca6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "# Select first wikitable on page\n",
    "wikipedia_growthrate = soup.find_all('table', class_='wikitable')[0]\n",
    "\n",
    "dates, article_count, article_increase, percent_increase, doubling_time, avg_increase_per_day = [], [], [], [], [], []\n",
    "for row in wikipedia_growthrate.find_all('tr'):\n",
    "    data = row.find_all('td')\n",
    "    if len(data) == 6 and all(x.text != \"â€”\" for x in data):\n",
    "        \n",
    "        # converts date data from table to datetime and adds it to list\n",
    "        dates.append(datetime.strptime(data[0].text.strip(), \"%Y-%m-%d\"))\n",
    "        \n",
    "        # converts article count data from table to int and adds it to list\n",
    "        article_count.append(int(data[1].text.strip().replace(\",\", \"\")))\n",
    "        \n",
    "        # converts article increase data from table to int and adds it to list\n",
    "        article_increase.append(int(data[2].find(text=True).strip().replace(\",\", \"\")))\n",
    "        \n",
    "        # converts percentage data from table to float and adds it to list\n",
    "        percent_increase.append(float(data[3].find(text=True).replace(\"%\", \"\")))\n",
    "        \n",
    "        # converts string of double time to timedelta object and adds it to list\n",
    "        double_time_regex = re.search(\"((\\d+) years?, )?(\\d+) days?|(\\d+) years?\", data[4].text.replace(\"\\xa0\", \" \"))\n",
    "        if double_time_regex.groups()[3]:\n",
    "            double_time = timedelta(days=(365 * int(double_time_regex.groups()[3])))\n",
    "        else:\n",
    "            days = int(double_time_regex.groups()[2])\n",
    "            if double_time_regex.groups()[1]:\n",
    "                days += int(double_time_regex.groups()[1]) * 365\n",
    "            double_time = timedelta(days=days)\n",
    "        doubling_time.append(double_time)\n",
    "        \n",
    "        # converts average increase/day data to int and adds it to list\n",
    "        avg_increase_per_day.append(int(data[5].find(text=True).strip()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "acda7919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Article Count  Article Increase  Percent Increase  \\\n",
      "0  2003-01-01          96500             76800            390.00   \n",
      "1  2004-01-01         188800             92300             96.00   \n",
      "2  2005-01-01         438500            249700            132.00   \n",
      "3  2006-01-01         895000            456500            104.00   \n",
      "4  2007-01-01        1560000            665000             74.00   \n",
      "5  2008-01-01        2153000            593000             38.00   \n",
      "6  2009-01-01        2679000            526000             24.00   \n",
      "7  2010-01-01        3144000            465000             17.00   \n",
      "8  2011-01-01        3518000            374000             12.00   \n",
      "9  2012-01-01        3835000            317000              9.00   \n",
      "10 2013-01-01        4133000            298000              8.00   \n",
      "11 2014-01-01        4413000            280000              7.00   \n",
      "12 2015-01-01        4682000            269000              6.00   \n",
      "13 2016-01-01        5045000            363000              8.00   \n",
      "14 2017-01-01        5321200            276200              7.00   \n",
      "15 2018-01-01        5541900            220700              4.50   \n",
      "16 2019-01-01        5773600            231700              4.20   \n",
      "17 2020-01-01        5989400            215800              3.75   \n",
      "18 2021-01-01        6219700            230300              3.80   \n",
      "19 2022-01-01        6431400            211700              3.40   \n",
      "20 2022-04-19        6486435             54969              0.85   \n",
      "\n",
      "   Doubling Time  Avg Increase in Articles per Day  \n",
      "0       160 days                               210  \n",
      "1       377 days                               253  \n",
      "2       301 days                               682  \n",
      "3       355 days                              1251  \n",
      "4       342 days                              1822  \n",
      "5       667 days                              1625  \n",
      "6      1056 days                              1437  \n",
      "7      1489 days                              1274  \n",
      "8      2109 days                              1025  \n",
      "9      2812 days                               868  \n",
      "10     3163 days                               814  \n",
      "11     3615 days                               767  \n",
      "12     4217 days                               736  \n",
      "13     3163 days                               995  \n",
      "14     3615 days                               755  \n",
      "15     5623 days                               605  \n",
      "16     6150 days                               635  \n",
      "17     7311 days                               591  \n",
      "18     7300 days                               629  \n",
      "19     7665 days                               580  \n",
      "20     7773 days                               509  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'Date': dates, 'Article Count': article_count,\n",
    "                   'Article Increase': article_increase, 'Percent Increase': percent_increase,\n",
    "                  'Doubling Time': doubling_time, 'Avg Increase in Articles per Day': avg_increase_per_day})\n",
    "\n",
    "# The instructions said to print at least the first 10 rows, but the data set is only 20 rows, so I just printed it all\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "680c1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe data as csv\n",
    "df.to_csv(\"CSC221-webscrape-data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
